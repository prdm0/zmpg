parallel = TRUE
) |>
hist(
main = "Generating Gaussian observations",
xlab = "x",
probability = TRUE
)
acceptance_rejection(
n = 10000L,
f = dbeta,
continuous = TRUE,
args_pdf = list(shape1 = 10, shape2 = 10),
xlim = c(0, 1),
parallel = TRUE
) |>
hist(
main = "Generating Gaussian observations",
xlab = "x",
probability = TRUE
)
rbeta(10000, 20, 20) |> hist()
acceptance_rejection(
n = 10000L,
f = dbeta,
continuous = TRUE,
args_pdf = list(shape1 = 10, shape2 = 10),
xlim = c(0, 1),
parallel = TRUE
) |>
hist(
main = "Generating Gaussian observations",
xlab = "x",
probability = TRUE
)
acceptance_rejection(
n = 10000L,
f = dbeta,
continuous = TRUE,
args_pdf = list(shape1 = 0.0010, shape2 = 10),
xlim = c(0, 1),
parallel = TRUE
) |>
hist(
main = "Generating Gaussian observations",
xlab = "x",
probability = TRUE
)
acceptance_rejection(
n = 100L,
f = dbeta,
continuous = TRUE,
args_pdf = list(shape1 = 0.0010, shape2 = 10),
xlim = c(0, 1),
parallel = TRUE
) |>
hist(
main = "Generating Gaussian observations",
xlab = "x",
probability = TRUE
)
acceptance_rejection(
n = 2000L,
f = dbeta,
continuous = TRUE,
args_pdf = list(shape1 = 0.0010, shape2 = 10),
xlim = c(0, 1),
parallel = TRUE
) |>
hist(
main = "Generating Gaussian observations",
xlab = "x",
probability = TRUE
)
Sys.info()
restricao_rho <- function(mu, phi){
c(0, 1 / (1 - exp(-mu/(1 + mu * phi))))
}
restricao_rho(10.7, 4.5)
library(LambertW)
# install.packages("remotes")
# remotes::install_github("prdm0/zmpg", force = TRUE)
library(zmpg)
# Parametros verdadeiros
mu = 10.7
phi = 4.5
rho = 3.2
lambda = 1.4
invervalo_geracao <- c(0, 5)
restricao_rho <- function(mu, phi){
c(0, 1 / (1 - exp(-mu/(1 + mu * phi))))
}
# Densidade de Katy
pdf <- function(x, mu, phi, rho, lambda) {
s0 <- exp(-lambda * x)
delta <- (mu * phi)/(1 + mu * phi)
kapa <- LambertW::W(-delta * s0 * exp(-delta))
h0 <- lambda
-rho * h0 * exp(-1/phi * (kapa + delta))/phi * kapa/(1 + kapa)
}
# c <- integrate(
#   \(x) pdf(x, mu = mu, phi = phi, rho = rho, lambda = lambda),
#   lower = 0,
#   upper = 15
# )$value
#
# # Chegando a padronizacao
# integrate(
#   \(x) pdf(x, mu = mu, phi = phi, rho = rho, lambda = lambda)/c,
#   lower = 0,
#   upper = 15
# )
set.seed(0) # Garantindo reprodutibilidade
dados <- acceptance_rejection(
n = 5000L,
f = pdf, #\(...) pdf(...)/c,
continuous = TRUE,
args_pdf = list(mu = mu, phi = phi, rho = rho, lambda = lambda),
xlim = invervalo_geracao,
parallel = TRUE
)
x <- seq(invervalo_geracao[1L], invervalo_geracao[2L], length.out = 500L)
y <- pdf(x = x, mu = mu, phi = phi, rho = rho, lambda = lambda)/c
library(LambertW)
# install.packages("remotes")
# remotes::install_github("prdm0/zmpg", force = TRUE)
library(zmpg)
# Parametros verdadeiros
mu = 10.7
phi = 4.5
rho = 3.2
lambda = 1.4
invervalo_geracao <- c(0, 5)
restricao_rho <- function(mu, phi){
c(0, 1 / (1 - exp(-mu/(1 + mu * phi))))
}
# Densidade de Katy
pdf <- function(x, mu, phi, rho, lambda) {
s0 <- exp(-lambda * x)
delta <- (mu * phi)/(1 + mu * phi)
kapa <- LambertW::W(-delta * s0 * exp(-delta))
h0 <- lambda
-rho * h0 * exp(-1/phi * (kapa + delta))/phi * kapa/(1 + kapa)
}
set.seed(0) # Garantindo reprodutibilidade
dados <- acceptance_rejection(
n = 500L,
f = pdf, #\(...) pdf(...)/c,
continuous = TRUE,
args_pdf = list(mu = mu, phi = phi, rho = rho, lambda = lambda),
xlim = invervalo_geracao,
parallel = TRUE
)
hist(dados)
x <- seq(invervalo_geracao[1L], invervalo_geracao[2L], length.out = 500L)
y <- pdf(x = x, mu = mu, phi = phi, rho = rho, lambda = lambda)/c
x <- seq(invervalo_geracao[1L], invervalo_geracao[2L], length.out = 500L)
y <- pdf(x = x, mu = mu, phi = phi, rho = rho, lambda = lambda)
hist(
dados,
probability = TRUE,
ylim = c(0, 1.5)
)
# Plotando curva verdadeira sobre os dados gerado
lines(x, y, col = "red", lwd = 2)
likelihood <- function(x, mu, phi, rho, lambda){
-sum(log(pdf(x = x, mu = mu, phi = phi, rho = rho, lambda = lambda)))
}
optim(
par = c(1),
fn = \(theta) likelihood(x = dados, mu = mu, phi = phi, rho = rho, lambda = theta),
method = "L-BFGS-B",
lower = 0,
upper = 10
)$par
library(LambertW)
# install.packages("remotes")
# remotes::install_github("prdm0/zmpg", force = TRUE)
library(zmpg)
# Parametros verdadeiros
mu = 10.7
phi = 4.5
rho = 3.2
lambda = 1.4
invervalo_geracao <- c(0, 5)
restricao_rho <- function(mu, phi){
c(0, 1 / (1 - exp(-mu/(1 + mu * phi))))
}
# Densidade de Katy
pdf <- function(x, mu, phi, rho, lambda) {
s0 <- exp(-lambda * x)
delta <- (mu * phi)/(1 + mu * phi)
kapa <- LambertW::W(-delta * s0 * exp(-delta))
h0 <- lambda
-rho * h0 * exp(-1/phi * (kapa + delta))/phi * kapa/(1 + kapa)
}
# c <- integrate(
#   \(x) pdf(x, mu = mu, phi = phi, rho = rho, lambda = lambda),
#   lower = 0,
#   upper = 15
# )$value
#
# # Chegando a padronizacao
# integrate(
#   \(x) pdf(x, mu = mu, phi = phi, rho = rho, lambda = lambda)/c,
#   lower = 0,
#   upper = 15
# )
set.seed(0) # Garantindo reprodutibilidade
dados <- acceptance_rejection(
n = 500L,
f = pdf, #\(...) pdf(...)/c,
continuous = TRUE,
args_pdf = list(mu = mu, phi = phi, rho = rho, lambda = lambda),
xlim = invervalo_geracao,
parallel = TRUE
)
x <- seq(invervalo_geracao[1L], invervalo_geracao[2L], length.out = 500L)
y <- pdf(x = x, mu = mu, phi = phi, rho = rho, lambda = lambda)
hist(
dados,
probability = TRUE,
ylim = c(0, 1.5)
)
# Plotando curva verdadeira sobre os dados gerado
lines(x, y, col = "red", lwd = 2)
# zmpg_exp <- zmpg::pdf_fragility_zmpg(dexp)
likelihood <- function(x, mu, phi, rho, lambda){
-sum(log(pdf(x = x, mu = mu, phi = phi, rho = rho, lambda = lambda)))
}
optim(
par = c(1),
fn = \(theta) likelihood(x = dados, mu = mu, phi = theta, rho = rho, lambda = lambda),
method = "L-BFGS-B",
lower = 0,
upper = 10
)$par
remotes::install_github("rjournal/rjtools")
library(zmpg)
?pdf_fragility_zmpg
pdf_zmpg <- zmpg::pdf_fragility_zmpg(dexp)
pdf_zmpg
library(LambertW)
# install.packages("remotes")
# remotes::install_github("prdm0/zmpg", force = TRUE)
library(zmpg)
# Parametros verdadeiros
mu = 10.7
phi = 4.5
rho = 3.2
lambda = 1.4
invervalo_geracao <- c(0, 5)
restricao_rho <- function(mu, phi){
c(0, 1 / (1 - exp(-mu/(1 + mu * phi))))
}
# Densidade de Katy
pdf <- function(x, mu, phi, rho, lambda) {
s0 <- exp(-lambda * x)
delta <- (mu * phi)/(1 + mu * phi)
kapa <- LambertW::W(-delta * s0 * exp(-delta))
h0 <- lambda
-rho * h0 * (exp(-1/phi * (kapa + delta))/phi) * kapa/(1 + kapa)
}
# Densidade do pacote zmpg
pdf_zmpg <- zmpg::pdf_fragility_zmpg(dexp)
pdf_zmpg(0.22, mu = mu, phi = phi, rho = rho, lambda = lambda)
# Densidade do pacote zmpg
pdf_zmpg <- zmpg::pdf_fragility_zmpg(dexp)
pdf_zmpg(0.22, mu = mu, phi = phi, rho = rho, rate = lambda)
# Densidad de Katy
pdf(0.22, mu = mu, phi = phi, rho = rho, lambda = lambda)
install.packages("grateful")
?dweibull
library(AcceptReject)
dados <-
accept_reject(
n = 1000,
continuous = TRUE,
f = dweibull,
args_f = list(shape = 1.4, scale = 2.3)
)
dados
library(AcceptReject)
dados <-
accept_reject(
n = 1000, # Número de dados a serem gerados
continuous = TRUE,
f = dweibull,
args_f = list(shape = 2.4, scale = 2.7), # Parâmetros da distribuição Weibull
xlim = c(0, 10) # Suporte
)
# Checando os dados gerados com a distribuição teórica
plot(dados)
# Função de verossimilhança
log_likelihood <- function(x, shape, scale){
-sum(log(dweibull(x, shape = shape, scale = scale)))
}
# Minimizando a função de verossimilhança
optim(
par = c(0.5, 0.5),
fn = \(theta) log_likelihood(x = dados, shape = theta[1L], scale = theta[2L]),
method = "L-BFGS-B",
lower = 0,
upper = 10
)$par
hist(dados)
library(AcceptReject)
library(zmpg)
# Gerando dados da ZMPG-Exponencial
dados <-
accept_reject(
n = 1000, # Número de dados a serem gerados
continuous = TRUE,
f = zmpg::pdf_fragility_zmpg(dexp),
args_f = list(mu = 10.7, phi = 4.5, rho = 3.2, rate = 1.4), # Parâmetros da ZMPG
xlim = c(0, 5),
parallel = TRUE # Paralelizando em sistemas Unix
)
pdf <- function(x, mu, phi, rho, lambda) {
s0 <- exp(-lambda * x)
delta <- (mu * phi)/(1 + mu * phi)
kapa <- LambertW::W(-delta * s0 * exp(-delta))
h0 <- lambda
-rho * h0 * (exp(-1/phi * (kapa + delta))/phi) * kapa/(1 + kapa)
}
pdf(0.22, mu = mu, phi = phi, rho = rho, lambda = lambda)
pdf <- function(x, mu, phi, rho, lambda) {
s0 <- exp(-lambda * x)
delta <- (mu * phi)/(1 + mu * phi)
kapa <- LambertW::W(-delta * s0 * exp(-delta))
h0 <- lambda
-rho * h0 * (exp(-1/phi * (kapa + delta))/phi) * kapa/(1 + kapa)
}
pdf(0, mu = mu, phi = phi, rho = rho, lambda = lambda)
library(AcceptReject)
# Gerando dados da ZMPG-Exponencial
dados <-
accept_reject(
n = 1000, # Número de dados a serem gerados
continuous = TRUE,
f = pdf,
args_f = list(mu = 10.7, phi = 4.5, rho = 3.2, lambda = 1.4), # Parâmetros da ZMPG
xlim = c(0.00, 5),
parallel = TRUE # Paralelizando em sistemas Unix
)
dados
hist(dados)
hist(dados)
hist(dados)
hist(dados, probability = TRUE, breaks = 30, col = "lightblue", main = "Histograma dos dados gerados"))
hist(dados, probability = TRUE, breaks = 30, col = "lightblue", main = "Histograma dos dados gerados")
hist(dados, probability = TRUE, breaks = 30, col = "lightblue", main = "Histograma dos dados gerados")
dados <-
accept_reject(
n = 1000, # Número de dados a serem gerados
continuous = TRUE,
f = pdf,
args_f = list(mu = 10.7, phi = 4.5, rho = 3.2, lambda = 1.4), # Parâmetros da ZMPG
xlim = c(0, 10),
parallel = TRUE # Paralelizando em sistemas Unix
)
hist(dados, probability = TRUE, breaks = 30, col = "lightblue", main = "Histograma dos dados gerados")
library(AcceptReject)
# Gerando dados da ZMPG-Exponencial
dados <-
accept_reject(
n = 1000, # Número de dados a serem gerados
continuous = TRUE,
f = pdf,
args_f = list(mu = 10.7, phi = 4.5, rho = 3.2, lambda = 1.4), # Parâmetros da ZMPG
xlim = c(0, 5),
parallel = TRUE # Paralelizando em sistemas Unix
)
hist(dados, probability = TRUE, breaks = 30, col = "lightblue", main = "Histograma dos dados gerados")
library(AcceptReject)
# Parâmetros verdadeiros
mu = 10.7
phi = 4.5
rho = 3.2
lambda = 1.4
# Gerando dados da ZMPG-Exponencial
dados <-
accept_reject(
n = 1000, # Número de dados a serem gerados
continuous = TRUE,
f = pdf,
args_f = list(mu = mu, phi = phi, rho = rho, lambda = lambda), # Parâmetros da ZMPG
xlim = c(0, 5),
parallel = TRUE # Paralelizando em sistemas Unix
)
log_likelihood <- function(x, mu, phi, rho, lambda){
-sum(log(pdf(x, mu = mu, phi = phi, rho = rho, lambda = lambda)))
}
estimativas <-
optim(
par = c(0.5, 0.5, 0.5, 0.5),
fn = \(theta) log_likelihood(x = dados, mu = theta[1L], phi = theta[2L], rho = theta[3L], lambda = theta[4L]),
method = "L-BFGS-B",
lower = 0,
upper = 5
)$par
# Função de verossimilhança
log_likelihood <- function(x, shape, scale){
-sum(log(dweibull(x, shape = shape, scale = scale)))
}
# Minimizando a função de verossimilhança
estimativas <-
optim(
par = c(0.5, 0.5),
fn = \(theta) log_likelihood(x = dados, shape = theta[1L], scale = theta[2L]),
method = "L-BFGS-B",
lower = 0,
upper = 10
)$par
set.seed(0)
dados <-
accept_reject(
n = 1000, # Número de dados a serem gerados
continuous = TRUE,
f = dweibull,
args_f = list(shape = 2.4, scale = 2.7), # Parâmetros da distribuição Weibull
xlim = c(0.0001, 5) # Suporte
)
# Checando os dados gerados com a distribuição teórica
plot(dados)
# Parametros verdadeiros
mu = 10.7
phi = 4.5
rho = 3.2
lambda = 1.4
# Densidade de Katy
pdf <- function(x, mu, phi, rho, lambda) {
s0 <- exp(-lambda * x)
delta <- (mu * phi)/(1 + mu * phi)
kapa <- LambertW::W(-delta * s0 * exp(-delta))
h0 <- lambda
-rho * h0 * (exp(-1/phi * (kapa + delta))/phi) * kapa/(1 + kapa)
}
pdf(0.22, mu = mu, phi = phi, rho = rho, lambda = lambda)
# Densidade do pacote zmpg
pdf_zmpg <- zmpg::pdf_fragility_zmpg(dexp)
pdf_zmpg(0.22, mu = mu, phi = phi, rho = rho, rate = lambda)
library(AcceptReject)
# Garantindo reprodutibilidade
set.seed(0)
dados <-
accept_reject(
n = 1000, # Número de dados a serem gerados
continuous = TRUE,
f = dweibull,
args_f = list(shape = 2.4, scale = 2.7), # Parâmetros da distribuição Weibull
xlim = c(0, 5) # Suporte
)
# Checando os dados gerados com a distribuição teórica
plot(dados)
library(AcceptReject)
# Garantindo reprodutibilidade
set.seed(0)
dados <-
accept_reject(
n = 1000, # Número de dados a serem gerados
continuous = TRUE,
f = dweibull,
args_f = list(shape = 2.4, scale = 2.7), # Parâmetros da distribuição Weibull
xlim = c(0, 10) # Suporte
)
# Checando os dados gerados com a distribuição teórica
plot(dados)
# Função de verossimilhança
log_likelihood <- function(x, shape, scale){
-sum(log(dweibull(x, shape = shape, scale = scale)))
}
# Minimizando a função de verossimilhança
estimativas <-
optim(
par = c(0.5, 0.5),
fn = \(theta) log_likelihood(x = dados, shape = theta[1L], scale = theta[2L]),
method = "L-BFGS-B",
lower = 0,
upper = 10
)$par
# As estimativas de máxima verossimilhança foram
print(estimativas)
library(AcceptReject)
# Parâmetros verdadeiros
mu = 10.7
phi = 4.5
rho = 3.2
lambda = 1.4
# Garantindo reprodutibilidade
set.seed(0)
# Gerando dados da ZMPG-Exponencial
dados <-
accept_reject(
n = 1000, # Número de dados a serem gerados
continuous = TRUE,
f = pdf,
args_f = list(mu = mu, phi = phi, rho = rho, lambda = lambda), # Parâmetros da ZMPG
xlim = c(0, 5),
parallel = TRUE # Paralelizando em sistemas Unix
)
log_likelihood <- function(x, mu, phi, rho, lambda){
-sum(log(pdf(x, mu = mu, phi = phi, rho = rho, lambda = lambda)))
}
estimativa <-
optim(
par = c(1),
fn = \(theta) log_likelihood(x = dados, mu = mu, phi = phi, rho = rho, lambda = theta),
method = "L-BFGS-B",
lower = 0,
upper = 5
)$par
dcauchy(0)
